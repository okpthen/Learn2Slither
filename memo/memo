学習率 Learning Rate
学習率は、Q値の更新時に新しい情報をどの程度反映させるかを決めるパラメータです。

割引率 Discount Factor
割引率は、将来の報酬をどの程度重視するかを決めるパラメータです。

探索率 Exploration Rate
グリーディポリシーで使われる探索率は、ランダムに行動する割合を示します。


ポリシーネットワーク
現在の行動ポリシー（どの行動を取るか）の基準となるネットワーク。
ポリシーネットワークの更新は、各ステップまたはミニバッチごとに行います。
各ステップごとに更新: 学習が進むたびにポリシーネットワークをすぐに更新する方法です。
ミニバッチごとに更新: 通常は、一定のステップ数（例：32ステップ）ごとにReplay Bufferからサンプリングしてミニバッチを作り、ポリシーネットワークを更新します。

ターゲットネットワーク
Q値更新の基準を提供します。
更新は、頻繁に更新するわけではなく、一定の間隔で行います。
Nステップごと: 例えば、1,000ステップごとにターゲットネットワークを更新する
エピソードごと: 学習が進んだ後、一定のエピソードごとにターゲットネットワークを更新する
更新（ポリシーネットワークのパラメータをターゲットネットワークにコピーする）

Replay Buffer
最も古い経験（つまり、最初に追加された経験）を削除して、新しい経験を追加するのが一般的です。

ステップ: エージェントが1回行動を取る単位。
バッチ: 複数のステップから得られたデータの集まり（Replay Bufferからサンプリング）。
エピソード: ステップの連続で構成され、環境が終了条件に達するまでの一連の流れ。
